n_layers=3
hidden_dim=32
learning_rate=0.002657002552991989
batch_size=1024
dropout=0.21930898070911053
weight_decay=0.00012428102549501906
optimizer=adam
activation=leaky_relu
scheduler=none
hidden_dims=[32, 32, 32]
dropout_rates=[0.21930898070911053, 0.21930898070911053, 0.21930898070911053, 0.21930898070911053]
