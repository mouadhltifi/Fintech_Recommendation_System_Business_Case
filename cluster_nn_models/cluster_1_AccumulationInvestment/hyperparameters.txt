n_layers=4
hidden_dim=512
learning_rate=0.001400709229389057
batch_size=64
dropout=0.42913124865067587
weight_decay=0.00030290321684851623
optimizer=adam
activation=elu
scheduler=cosine
hidden_dims=[512, 512, 512, 512]
dropout_rates=[0.42913124865067587, 0.42913124865067587, 0.42913124865067587, 0.42913124865067587, 0.42913124865067587]
