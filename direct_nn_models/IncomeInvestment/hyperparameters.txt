n_layers=3
hidden_dim=64
learning_rate=0.0030295754777856483
batch_size=32
dropout=0.41310260283280364
weight_decay=6.20115152246848e-05
optimizer=adamw
activation=elu
scheduler=cosine
hidden_dims=[64, 64, 64]
dropout_rates=[0.41310260283280364, 0.41310260283280364, 0.41310260283280364, 0.41310260283280364]
